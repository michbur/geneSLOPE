---
title: "Tutorial for GWAS with SLOPE"
author: "Piotr Sobczyk"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tutorial for GWAS with SLOPE}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Tutorial on performing GWAS with SLOPE

This tutorial will guide you on performing GWAS with SLOPE in three simple steps.

#### Reading the data

You need to provide paths to three files:

1. Phenotype file. By default this file is assumed to have six column. The
last one contains phenotype. For details see documentation of function
*readPhenotype*
2. .map file with information about snps. This file is not required, but is highly
recommended. Especially if you want to plot analysis results
3. .raw file with snps. We assume that snps were previously exported from PLINK with command 
**plink -\-file input -\-recodeAD -\-out output**  
where *input* is you name of .ped file. 

```{r, results='hide', message=FALSE}
library(cps)
famFile <- system.file("extdata", "plinkPhenotypeExample.fam", package = "cps")
mapFile <- system.file("extdata", "plinkMapExample.map", package = "cps")
snpsFile <- system.file("extdata", "plinkDataExample.raw", package = "cps")
```

```{r}
phe <- readPhenotype(filename = famFile, sep=";")
```

When you have phenotype you can move to reading snp data. 
Depending on data size reading SNPs may long time.
As data is very large, snps are filtered with their marginal test p-value.
All snps which p-values are larger than threshold *pValMax* will be truncated.

```{r, warning=FALSE}
screening <- readSNPs(snpsFile, mapFile, phe$y, pValMax = 0.05, chunk_size = 1e2,
                         verbose=FALSE)
```

Parameter *verbose=FALSE* suppresses progress bar. Default value is *TRUE*.

User can check what is result of screening

```{r}
summary(screening)
```

#### Clumping highly correlated genes

Next step is clumping. Highly correlated snps will be clustered. When *rho*
decreases so does number of clumps; however, clumps are getting larger.

```{r}
clumping <- clumpProcedure(screening, rho = 0.3, verbose = FALSE)
```

What is the result of clumping?

```{r}
summary(clumping)
```

We can also plot our results

```{r, warning=FALSE, fig.height=7, fig.width=7}
plot(clumping)
```

If we are interested in specific genome we can "zoom it"

```{r, warning=FALSE, fig.height=6, fig.width=6}
plot(clumping, 2)
```

#### Running SLOPE on result of clumping procedure

Last step of analysis is using SLOPE

```{r}
slope.result <- genSLOPE(clumping, fdr=0.1)
```

As before one can plot and summarize results

```{r, warning = FALSE, fig.height=7, fig.width=7}
summary(slope.result)
plot(slope.result)
```

#### Detailed description of parameters

There are three numerical parameters that influence result

* *pValMax* is the threshold p-value for marginal test. When data is loaded to R,
initial screening of snps is performed. For every snp, test for coefficient in simple linear regression model *lm(phenotype~snp)* is performed. All snps with p-value larger than pValMax are discarded. Setting this parameter to too large will significantly increase number of snps on which clumping procedure will be performed. This may cause two technical threats
    * Computer might run out of RAM memory
    * Clumping procedure might take a lot of time
* *rho* is threshold for correlation between snps in clumping procedure. For given snp, every that is correlated with it at least at level *rho* will be clumped together. Setting this parameter too high (say 0.7) will cause SLOPE to work on highly correlated snps which might affect its accuracy
* *fdr* false discover rate for SLOPE procedure. The higher FDR is, more variables will be accepted to the model. Contrary, small fdr yields more conservative models

